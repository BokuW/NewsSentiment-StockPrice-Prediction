{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec196034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/03_Correlation_Analysis.ipynb - Consolidated Code\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob # For sentiment analysis\n",
    "\n",
    "# --- Project Setup: Ensure src module is discoverable ---\n",
    "def find_project_root(current_path):\n",
    "    path = current_path\n",
    "    while path != os.path.dirname(path):\n",
    "        if (os.path.isdir(os.path.join(path, 'src')) and\n",
    "            os.path.isdir(os.path.join(path, 'data')) and\n",
    "            os.path.isdir(os.path.join(path, 'notebooks'))):\n",
    "            return path\n",
    "        path = os.path.dirname(path)\n",
    "    return current_path\n",
    "\n",
    "current_working_dir = os.getcwd()\n",
    "project_root = find_project_root(current_working_dir)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added '{project_root}' to sys.path for module imports.\")\n",
    "else:\n",
    "    print(f\"'{project_root}' already in sys.path.\")\n",
    "\n",
    "# Import configuration variables from your src.config\n",
    "from src.config import NEWS_RAW_PATH, STOCK_DATA_DIR, STOCK_TICKERS\n",
    "\n",
    "print(\"\\n--- Starting Task 3: Correlation Analysis (All Tickers) ---\")\n",
    "\n",
    "# --- Load News Data (Once) ---\n",
    "print(\"\\n--- Loading News Data (Full Dataset) ---\")\n",
    "try:\n",
    "    # Do NOT parse_dates here, handle it in next step for mixed formats\n",
    "    news_df_raw = pd.read_csv(NEWS_RAW_PATH) \n",
    "    print(\"News data loaded successfully.\")\n",
    "    print(f\"News DataFrame Info (initial load):\\n{news_df_raw.info()}\") # Added \\n for cleaner output\n",
    "    print(\"\\nFirst 5 rows of News data (initial load):\")\n",
    "    print(news_df_raw.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"CRITICAL ERROR: News data file not found at {NEWS_RAW_PATH}.\")\n",
    "    sys.exit(\"Exiting: News data file not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: Could not load news data: {e}\")\n",
    "    sys.exit(\"Exiting: News data loading failed.\")\n",
    "\n",
    "if news_df_raw.empty:\n",
    "    sys.exit(\"Exiting: News DataFrame is empty after loading.\")\n",
    "\n",
    "\n",
    "# --- Function for Date Alignment and Sentiment Analysis ---\n",
    "# Encapsulating this logic as it will be applied per stock-news subset\n",
    "def prepare_news_and_stock_data_for_correlation(news_data, stock_data, ticker_symbol):\n",
    "    print(f\"\\n--- Preparing data for {ticker_symbol} ---\")\n",
    "\n",
    "    # Filter news for the current ticker\n",
    "    ticker_news_df = news_data[news_data['stock'] == ticker_symbol].copy()\n",
    "    if ticker_news_df.empty:\n",
    "        print(f\"No news data found for ticker {ticker_symbol}. Skipping correlation.\")\n",
    "        return pd.DataFrame() # Return empty DataFrame\n",
    "\n",
    "    # 1. Process News DataFrame 'date' column\n",
    "    # Step 1.1: Convert to datetime, coercing errors, and using 'mixed' format with utc=True\n",
    "    # This is the CRITICAL FIX. It forces datetime64[ns, UTC] dtype even with mixed offsets.\n",
    "    ticker_news_df['date'] = pd.to_datetime(ticker_news_df['date'], errors='coerce', format='mixed', utc=True)\n",
    "    \n",
    "    # Step 1.2: IMMEDIATELY drop rows where date conversion failed (became NaT)\n",
    "    initial_rows = len(ticker_news_df)\n",
    "    ticker_news_df.dropna(subset=['date'], inplace=True)\n",
    "    if len(ticker_news_df) < initial_rows:\n",
    "        print(f\"Dropped {initial_rows - len(ticker_news_df)} rows from news_df for {ticker_symbol} due to unparseable dates.\")\n",
    "    \n",
    "    # Verify dtype after initial conversion and dropna\n",
    "    print(f\"  news_df['date'] dtype after initial conversion and dropna: {ticker_news_df['date'].dtype}\")\n",
    "\n",
    "    # Step 1.3: Convert to timezone-naive (strip timezone) for daily alignment\n",
    "    # This is safe now because utc=True ensured it's datetime64[ns, UTC]\n",
    "    ticker_news_df['date'] = ticker_news_df['date'].dt.tz_localize(None)\n",
    "    print(f\"  News dates for {ticker_symbol} converted to timezone-naive UTC representation.\")\n",
    "\n",
    "    # Step 1.4: Extract only the date part (YYYY-MM-DD) for daily alignment\n",
    "    ticker_news_df['date_only'] = ticker_news_df['date'].dt.floor('D')\n",
    "    \n",
    "    # Step 1.5: Set 'date_only' as the index for news_df for merging\n",
    "    ticker_news_df.set_index('date_only', inplace=True)\n",
    "    ticker_news_df.sort_index(inplace=True)\n",
    "\n",
    "    # 2. Process Stock DataFrame Index\n",
    "    stock_data.index = stock_data.index.floor('D')\n",
    "    stock_data.sort_index(inplace=True)\n",
    "\n",
    "    # 3. Aggregate news headlines by date (if multiple on same day)\n",
    "    daily_news_headlines = ticker_news_df.groupby(ticker_news_df.index)['headline'].apply(lambda x: ' '.join(x)).rename('combined_headline')\n",
    "\n",
    "    # 4. Merge aggregated daily news headlines with daily stock data\n",
    "    merged_df = pd.merge(\n",
    "        stock_data,\n",
    "        daily_news_headlines,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how='inner'\n",
    "    )\n",
    "    if merged_df.empty:\n",
    "        print(f\"  Merged DataFrame is empty for {ticker_symbol}. No common dates found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- Sentiment Analysis ---\n",
    "    def get_sentiment_polarity(text):\n",
    "        if pd.isna(text):\n",
    "            return 0.0\n",
    "        return TextBlob(str(text)).sentiment.polarity\n",
    "    \n",
    "    merged_df['sentiment_score'] = merged_df['combined_headline'].apply(get_sentiment_polarity)\n",
    "\n",
    "    # --- Calculate Daily Stock Returns ---\n",
    "    merged_df['Daily_Return'] = merged_df['Close'].pct_change()\n",
    "    \n",
    "    # Prepare final correlation_df\n",
    "    correlation_df = merged_df[['Daily_Return', 'sentiment_score']].dropna()\n",
    "    \n",
    "    print(f\"  Data prepared for {ticker_symbol}. Correlation DataFrame shape: {correlation_df.shape}\")\n",
    "    return correlation_df\n",
    "\n",
    "\n",
    "# --- Main Loop for All Tickers ---\n",
    "all_tickers_correlation_results = {}\n",
    "for ticker in STOCK_TICKERS:\n",
    "    # Load stock data for current ticker\n",
    "    stock_file_name = f\"{ticker}_historical_data.csv\"\n",
    "    stock_file_path = os.path.join(STOCK_DATA_DIR, stock_file_name)\n",
    "    \n",
    "    try:\n",
    "        current_stock_df = pd.read_csv(stock_file_path, parse_dates=True, index_col='Date')\n",
    "        current_stock_df.columns = [col.replace(' ', '_') for col in current_stock_df.columns]\n",
    "        if 'Adj_Close' in current_stock_df.columns and 'Close' not in current_stock_df.columns:\n",
    "            current_stock_df['Close'] = current_stock_df['Adj_Close']\n",
    "        current_stock_df.dropna(inplace=True)\n",
    "        print(f\"\\nStock data for {ticker} loaded. Shape: {current_stock_df.shape}\") # Added \\n for cleaner output\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nERROR: Stock data for {ticker} not found at {stock_file_path}. Skipping.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: An unexpected error occurred loading stock data for {ticker}: {e}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Prepare data for current ticker\n",
    "    correlation_data_for_ticker = prepare_news_and_stock_data_for_correlation(news_df_raw, current_stock_df, ticker)\n",
    "\n",
    "    if not correlation_data_for_ticker.empty:\n",
    "        # --- Correlation Analysis ---\n",
    "        correlation = correlation_data_for_ticker['Daily_Return'].corr(correlation_data_for_ticker['sentiment_score'])\n",
    "        all_tickers_correlation_results[ticker] = correlation\n",
    "        \n",
    "        print(f\"\\nPearson Correlation between Average Daily News Sentiment and {ticker} Daily Returns: {correlation:.4f}\")\n",
    "\n",
    "        abs_correlation = abs(correlation)\n",
    "        if abs_correlation >= 0.7:\n",
    "            print(\"Interpretation: Strong correlation.\")\n",
    "        elif abs_correlation >= 0.5:\n",
    "            print(\"Interpretation: Moderate correlation.\")\n",
    "        elif abs_correlation >= 0.3:\n",
    "            print(\"Interpretation: Weak correlation.\")\n",
    "        else:\n",
    "            print(\"Interpretation: Very weak or no linear correlation.\")\n",
    "\n",
    "        if correlation > 0:\n",
    "            print(\"Direction: Positive.\")\n",
    "        elif correlation < 0:\n",
    "            print(\"Direction: Negative.\")\n",
    "        else:\n",
    "            print(\"Direction: No linear relationship.\")\n",
    "        print(\"Important Note: Correlation does not imply causation!\")\n",
    "\n",
    "\n",
    "        # --- Visualization of Correlation ---\n",
    "        print(f\"\\n--- Visualizing Sentiment vs. Returns for {ticker} ---\")\n",
    "        \n",
    "        # Scatter Plot\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.scatterplot(x='sentiment_score', y='Daily_Return', data=correlation_data_for_ticker, alpha=0.6)\n",
    "        plt.title(f'Average Daily News Sentiment vs. {ticker} Daily Returns (N={len(correlation_data_for_ticker)})')\n",
    "        plt.xlabel('Average Daily Sentiment Score (TextBlob Polarity)')\n",
    "        plt.ylabel('Daily Stock Return (%)')\n",
    "        plt.grid(True)\n",
    "        plt.axvline(0, color='gray', linestyle='--', linewidth=0.8, label='Neutral Sentiment')\n",
    "        plt.axhline(0, color='gray', linestyle='--', linewidth=0.8, label='Zero Return')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Time series plots of Sentiment and Returns\n",
    "        plt.figure(figsize=(16, 10))\n",
    "\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(correlation_data_for_ticker.index, correlation_data_for_ticker['sentiment_score'], label='Average Daily Sentiment', color='blue', alpha=0.7)\n",
    "        plt.title(f'{ticker} Average Daily Sentiment Over Time')\n",
    "        plt.ylabel('Sentiment Score')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(correlation_data_for_ticker.index, correlation_data_for_ticker['Daily_Return'], label='Daily Return', color='green', alpha=0.7)\n",
    "        plt.title(f'{ticker} Daily Returns Over Time')\n",
    "        plt.ylabel('Return')\n",
    "        plt.xlabel('Date')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Skipping visualization for {ticker}: No data available for correlation.\")\n",
    "\n",
    "print(\"\\n--- All Correlation Analysis for Task 3 Complete ---\")\n",
    "print(\"\\nSummary of Pearson Correlations:\")\n",
    "for ticker, corr in all_tickers_correlation_results.items():\n",
    "    print(f\"{ticker}: {corr:.4f}\")\n",
    "\n",
    "print(\"Remember to commit your work with descriptive messages to your 'task-3' branch!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
