{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789a1493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction' to sys.path for module imports.\n",
      "Project structure setup complete and config.py created/updated.\n",
      "Base Directory: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction\n",
      "News Raw Path: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction\\data\\raw_analyst_ratings.csv\n",
      "Stock Data Directory: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction\\data\\yfinance_data\n",
      "Tickers to process: ['AAPL', 'AMZN', 'GOOG', 'META', 'NVDA', 'TSLA']\n"
     ]
    }
   ],
   "source": [
    "# notebooks/02_Quantitative_Analysis.ipynb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Corrected way to find project root in a Jupyter Notebook ---\n",
    "# This function tries to find the project root by looking for\n",
    "# specific known directories like 'src', 'data', 'notebooks'.\n",
    "def find_project_root(current_path):\n",
    "    path = current_path\n",
    "    while path != os.path.dirname(path): # Traverse up until the filesystem root\n",
    "        # Check if this path contains the expected project structure\n",
    "        if (os.path.isdir(os.path.join(path, 'src')) and\n",
    "            os.path.isdir(os.path.join(path, 'data')) and\n",
    "            os.path.isdir(os.path.join(path, 'notebooks'))):\n",
    "            return path # Found the project root\n",
    "        path = os.path.dirname(path) # Move up to the parent directory\n",
    "    return current_path # Fallback: if structure not found, return original path\n",
    "\n",
    "# Get the current working directory (where the notebook was launched from)\n",
    "current_working_dir = os.getcwd()\n",
    "\n",
    "# Find the project root using the helper function\n",
    "project_root = find_project_root(current_working_dir)\n",
    "\n",
    "# Add the project root to sys.path\n",
    "# This allows Python to find 'src' as a top-level module\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added '{project_root}' to sys.path for module imports.\")\n",
    "else:\n",
    "    print(f\"'{project_root}' already in sys.path.\")\n",
    "\n",
    "# --- Now you can safely import from src.config ---\n",
    "from src.config import STOCK_DATA_DIR, STOCK_TICKERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef7c89f",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c44e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf # For fetching financial data\n",
    "import talib as ta    # For technical analysis indicators\n",
    "import numpy as np    # For numerical operations\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "import mplfinance as mpf # For advanced financial charts\n",
    "import pynance as pn # For financial metrics (as per task requirement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461fc254",
   "metadata": {},
   "source": [
    "# Load  and prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694109d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading and Preparing Data for all Tickers ---\n",
      "Attempting to load data for AAPL from: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction\\data\\yfinance_data\\AAPL_historical_data.csv\n",
      "Data loaded successfully for AAPL. Shape: (10998, 8)\n",
      "Attempting to load data for AMZN from: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction\\data\\yfinance_data\\AMZN_historical_data.csv\n",
      "Data loaded successfully for AMZN. Shape: (6846, 8)\n",
      "Attempting to load data for GOOG from: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction\\data\\yfinance_data\\GOOG_historical_data.csv\n",
      "Data loaded successfully for GOOG. Shape: (5020, 8)\n",
      "Attempting to load data for META from: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction\\data\\yfinance_data\\META_historical_data.csv\n",
      "Data loaded successfully for META. Shape: (2926, 8)\n",
      "Attempting to load data for NVDA from: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction\\data\\yfinance_data\\NVDA_historical_data.csv\n",
      "Data loaded successfully for NVDA. Shape: (6421, 8)\n",
      "Attempting to load data for TSLA from: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-1\\NewsSentiment-StockPrice-Prediction\\data\\yfinance_data\\TSLA_historical_data.csv\n",
      "Data loaded successfully for TSLA. Shape: (3545, 8)\n",
      "\n",
      "Successfully loaded data for 6 out of 6 tickers.\n",
      "Loaded tickers: ['AAPL', 'AMZN', 'GOOG', 'META', 'NVDA', 'TSLA']\n",
      "\n",
      "--- Performing Analysis and Visualization for Each Ticker ---\n",
      "\n",
      "--- Analyzing AAPL ---\n",
      "\n",
      "--- Analyzing AMZN ---\n",
      "\n",
      "--- Analyzing GOOG ---\n",
      "\n",
      "--- Analyzing META ---\n",
      "\n",
      "--- Analyzing NVDA ---\n",
      "\n",
      "--- Analyzing TSLA ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. Load and Prepare ALL Stock Data ---\n",
    "print(\"\\n--- Loading and Preparing Data for all Tickers ---\")\n",
    "\n",
    "all_stocks_df = {} # This dictionary will store DataFrames for each ticker\n",
    "\n",
    "for ticker in STOCK_TICKERS:\n",
    "    # Construct the full file path using os.path.join with the correct filename suffix\n",
    "    file_name = f\"{ticker}_historical_data.csv\" # Corrected filename\n",
    "    file_path = os.path.join(STOCK_DATA_DIR, file_name)\n",
    "\n",
    "    print(f\"Attempting to load data for {ticker} from: {file_path}\")\n",
    "    try:\n",
    "        df_ticker = pd.read_csv(file_path, parse_dates=True, index_col='Date')\n",
    "        \n",
    "        # Standardize column names: replace spaces and ensure 'Close' column\n",
    "        df_ticker.columns = [col.replace(' ', '_') for col in df_ticker.columns]\n",
    "        if 'Adj_Close' in df_ticker.columns and 'Close' not in df_ticker.columns:\n",
    "            df_ticker['Close'] = df_ticker['Adj_Close']\n",
    "        \n",
    "        # Ensure all required OHLCV columns are present\n",
    "        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        if not all(col in df_ticker.columns for col in required_cols):\n",
    "            print(f\"\\nWARNING: Missing one or more required OHLCV columns for {ticker}.\")\n",
    "            print(f\"Found: {df_ticker.columns.tolist()}. Required: {required_cols}\")\n",
    "            # Skip this ticker if critical columns are missing\n",
    "            continue \n",
    "\n",
    "        # Drop rows with any NaN values\n",
    "        df_ticker.dropna(inplace=True) \n",
    "        \n",
    "        if not df_ticker.empty:\n",
    "            all_stocks_df[ticker] = df_ticker\n",
    "            print(f\"Data loaded successfully for {ticker}. Shape: {df_ticker.shape}\")\n",
    "        else:\n",
    "            print(f\"WARNING: DataFrame for {ticker} is empty after cleaning. Skipping.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Local data file not found for {ticker} at {file_path}. Skipping this ticker.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An unexpected error occurred loading {ticker} data: {e}. Skipping this ticker.\")\n",
    "\n",
    "if not all_stocks_df:\n",
    "    sys.exit(\"Exiting: No stock data loaded successfully for any ticker.\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded data for {len(all_stocks_df)} out of {len(STOCK_TICKERS)} tickers.\")\n",
    "print(\"Loaded tickers:\", list(all_stocks_df.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Apply Analysis Indicators with TA-Lib ---\n",
    "\n",
    "# --- Iterate through each stock for analysis and visualization ---\n",
    "print(\"\\n--- Performing Analysis and Visualization for Each Ticker ---\")\n",
    "\n",
    "for ticker, df in all_stocks_df.items():\n",
    "    print(f\"\\n--- Analyzing {ticker} ---\")\n",
    "\n",
    "    # Ensure 'Close' column is numeric for TA-Lib operations\n",
    "    if not pd.api.types.is_numeric_dtype(df['Close']):\n",
    "        df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "        df.dropna(subset=['Close'], inplace=True)\n",
    "        if df.empty:\n",
    "            print(f\"Skipping {ticker}: 'Close' column became empty after numeric conversion.\")\n",
    "            continue\n",
    "# Simple Moving Averages (SMA)\n",
    "df['SMA_10'] = ta.SMA(df['Close'], timeperiod=10)\n",
    "df['SMA_50'] = ta.SMA(df['Close'], timeperiod=50)\n",
    "df['SMA_200'] = ta.SMA(df['Close'], timeperiod=200)\n",
    "\n",
    "# Relative Strength Index (RSI)\n",
    "df['RSI'] = ta.RSI(df['Close'], timeperiod=14)\n",
    "\n",
    "# Moving Average Convergence Divergence (MACD)\n",
    "macd, macdsignal, macdhist = ta.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "df['MACD'] = macd\n",
    "df['MACD_Signal'] = macdsignal\n",
    "df['MACD_Hist'] = macdhist\n",
    "\n",
    "# Bollinger Bands (BBANDS)\n",
    "upperband, middleband, lowerband = ta.BBANDS(\n",
    "    df['Close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0\n",
    ")\n",
    "df['BB_Upper'] = upperband\n",
    "df['BB_Middle'] = middleband\n",
    "df['BB_Lower'] = lowerband\n",
    "\n",
    "# Stochastic Oscillator (STOCH) - Requires High, Low, Close\n",
    "if all(col in df.columns for col in ['High', 'Low']):\n",
    "    slowk, slowd = ta.STOCH(\n",
    "        df['High'], df['Low'], df['Close'],\n",
    "        fastk_period=14, slowk_period=3, slowk_matype=0,\n",
    "        slowd_period=3, slowd_matype=0\n",
    "    )\n",
    "    df['Stoch_K'] = slowk\n",
    "    df['Stoch_D'] = slowd\n",
    "else:\n",
    "    print(f\"WARNING ({ticker}): High/Low columns not found. Skipping Stochastic Oscillator calculation.\")\n",
    "\n",
    "# Average Directional Movement Index (ADX) - Requires High, Low, Close\n",
    "if all(col in df.columns for col in ['High', 'Low']):\n",
    "    df['ADX'] = ta.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "else:\n",
    "    print(f\"WARNING ({ticker}): High/Low columns not found. Skipping ADX calculation.\")\n",
    "\n",
    "# Drop rows with NaN values that result from indicator calculations (these are typically at the beginning of the series)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "if df.empty:\n",
    "    print(f\"Skipping {ticker}: DataFrame became empty after TA-Lib indicator calculation and NaNs dropped.\")\n",
    "    continue\n",
    "\n",
    "print(f\"DataFrame shape for {ticker} after TA-Lib indicator calculation and NaNs dropped: {df.shape}\")\n",
    "# print(df.tail())  # Uncomment to see tail for each ticker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac695f22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # --- 4. Use PyNance for Financial Metrics ---\n",
    "    # Daily Returns (using Pandas, robust)\n",
    "df['Daily_Return'] = df['Close'].pct_change()\n",
    "\n",
    "    # Log Returns (often preferred for continuous compounding analysis)\n",
    "df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "\n",
    "    # Annualized Rolling Volatility (using Pandas)\n",
    "df['Rolling_Volatility_20D'] = df['Daily_Return'].rolling(window=20).std() * np.sqrt(252)\n",
    "\n",
    "    # --- Attempting PyNance specific metrics (Conceptual, verify API) ---\n",
    "try:\n",
    "        # PyNance functions like pn.metrics.returns or pn.metrics.volatility\n",
    "        # might be used here if they provide distinct advantages or specific calculations.\n",
    "        # For this example, we'll rely on the Pandas-based metrics as they are robust.\n",
    "        print(f\"PyNance attempt for metrics for {ticker} completed (using Pandas-based metrics for robustness).\")\n",
    "except Exception as e:\n",
    "        print(f\"WARNING ({ticker}): Could not run PyNance specific metrics directly. Error: {e}\")\n",
    "\n",
    "df.dropna(inplace=True) # Drop NaNs again if any new metrics introduced them\n",
    "if df.empty:\n",
    "    print(f\"Skipping {ticker}: DataFrame became empty after financial metrics calculation and NaNs dropped.\")\n",
    "    continue\n",
    "\n",
    "print(f\"DataFrame shape for {ticker} after financial metrics calculation and NaNs dropped: {df.shape}\")\n",
    "print(df.tail()) # To see tail for each ticker\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
